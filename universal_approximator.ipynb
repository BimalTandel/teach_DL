{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universality Proof\n",
    "A neural network with a single hidden layer can be used to approximate any [continuous] function.  \n",
    "As the number of neurons increases the approximation error decreases.\n",
    "In this visual demonstration we'll be using hidden neurons that use the sigmoid activation function.\n",
    "$$ sig(x) = \\frac{1}{1+e^{-x}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid ( input ):\n",
    "    return 1. / ( 1. + np.exp( -1. * input ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Neuron Activation [ Threshold ]\n",
    "By increasing the weight to the hidden unit from the input we can create a 'hard' threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace( 0, 1, 100)\n",
    "bias = 1\n",
    "\n",
    "# input neuron\n",
    "input_1 = x\n",
    "\n",
    "# hidden neuron 1\n",
    "bW_1 = -5\n",
    "w_1 = 10\n",
    "sum_1 = input_1 * w_1 + bias * bW_1\n",
    "activation_1 = sigmoid( sum_1 )\n",
    "\n",
    "# output neuron\n",
    "bW_output = 0\n",
    "w_2 = 1\n",
    "sum_output = activation_1 * w_2 + bias * bW_output\n",
    "output_activation = sigmoid( sum_output )\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = plt.subplot(3,1,1); plt.ylim([-0.1,1.1])\n",
    "ax2 = plt.subplot(3,1,2)\n",
    "ax3 = plt.subplot(3,1,3)\n",
    "\n",
    "ax1.plot(activation_1)\n",
    "ax2.plot(output_activation, 'g')\n",
    "\n",
    "import nnViz\n",
    "network = nnViz.NeuralNetwork()\n",
    "network.add_layer(1, np.array([[w_1]]))\n",
    "network.add_layer(1, np.array([[w_2]]))\n",
    "network.add_layer(1)\n",
    "network.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Neurons [ Bump ]\n",
    "By increasing the intial weights to the hidden layer to create hard thresholds, and creating pairs of hidden neurons that have inverse connections to the output, we are able to create 'bumps' with which we can approximate the target function. The bias neuron and its weights are used to determine the bump center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input neuron\n",
    "input_1 = x\n",
    "\n",
    "# hidden neuron 1\n",
    "bW_1 = -5\n",
    "w_1 = 100\n",
    "sum_1 = input_1 * w_1 + bias * bW_1\n",
    "activation_1 = sigmoid( sum_1 )\n",
    "\n",
    "# hidden neuron 2\n",
    "bW_2 = -50\n",
    "w_2 = 100\n",
    "sum_2 = input_1 * w_2 + bias * bW_2\n",
    "activation_2 = sigmoid( sum_2 )\n",
    "\n",
    "# output neuron\n",
    "bW_output = -5\n",
    "w_3 = 5\n",
    "w_4 = -5\n",
    "sum_output = activation_1 * w_3 + activation_2 * w_4 + bias * bW_output\n",
    "output_activation = sigmoid( sum_output )\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = plt.subplot(3,1,1); plt.ylim([-0.1,1.1])\n",
    "ax2 = plt.subplot(3,1,2); plt.ylim([-0.1,1.1])\n",
    "ax3 = plt.subplot(3,1,3)\n",
    "\n",
    "ax1.plot(activation_1); #plt.hold(True);\n",
    "ax1.plot(activation_2,'r')\n",
    "ax2.plot(output_activation, 'g')\n",
    "\n",
    "import nnViz\n",
    "network = nnViz.NeuralNetwork()\n",
    "network.add_layer(1, np.transpose(np.array([[w_1, w_2]])))\n",
    "network.add_layer(2, np.array([[w_3, w_4]]))\n",
    "network.add_layer(1)\n",
    "network.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Bumps\n",
    "When we combine multiple neuron pairs to create non-overlapping bumps we can cover the range of the function and adjust the bump heights to approximate the function with higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from universalNN import universalNN\n",
    "\n",
    "nn = universalNN()\n",
    "\n",
    "targetFunctionText = widgets.Text(); display( targetFunctionText )\n",
    "heightsText = widgets.Text(); display( heightsText )\n",
    "\n",
    "heightsText.on_submit( nn.textUpdateHeights )\n",
    "targetFunctionText.on_submit( nn.textUpdateTargetFunction )\n",
    "\n",
    "interact( nn.updatePairs, nPairs = FloatSlider(min=1, max=22, step=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.draw_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Examples '''\n",
    "# np.sin(self.x*np.pi*3)\n",
    "# 6.5, 7.7, 9, 11, 9, 7.7, 6.5, 6, 5, 4, 2, 2, 4, 5, 6, 6.5, 7.7, 9, 11, 9, 7.7, 6.5\n",
    "\n",
    "# np.exp(self.x*4)\n",
    "# 2.7, 3, 3.1, 3.2, 3.3, 3.4, 3.5, 3.7, 3.9, 4, 4.2, 4.4, 4.6, 4.8, 5, 5.2, 5.5, 5.7, 6.1, 6.4, 7, 7.9\n",
    "\n",
    "# np.sin(self.x*np.pi*3)+np.exp(self.x*self.x*self.x)-np.cos(self.x*10*np.pi)\n",
    "# ?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {
    "22b7839fc5374c0a89667aa8cbea21f5": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "39f34504293642b39348a52217b9714c": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "58fdb348d00c444a8ce6b2b088537aa4": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
