{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using ipympl instead.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numSyntheticSamples = 100000\n",
    "syntheticDataRange = np.linspace( 0, np.pi*numSyntheticSamples/10.0, numSyntheticSamples)\n",
    "syntheticData = np.sin( syntheticDataRange )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if syntheticData.ndim < 2:\n",
    "    syntheticData = np.expand_dims(syntheticData, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntheticData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfcc30e5c384495b74bd8ba2537992a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a84cde1518>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(syntheticData[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# of samples per sensor for the micro model [sliding window of ~2.5 hrs]\n",
    "hParams = {}\n",
    "hParams['windowSamples'] = 30\n",
    "hParams['nSensors'] = 1\n",
    "hParams['overlapPercentage'] = .99\n",
    "hParams['advanceSamples'] = ( hParams['windowSamples'] - int( np.floor( hParams['windowSamples'] * hParams['overlapPercentage'] ) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test set (.25 test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split (x, testDataRatio = .25, trainDataAtStart = True):\n",
    "    assert x.ndim > 1\n",
    "    if trainDataAtStart:\n",
    "        splitIndex = int( ( 1.0 - testDataRatio) * x.shape[0] )    \n",
    "        \n",
    "        xTrain = x[ 0:splitIndex, :]\n",
    "        xTest = x[ splitIndex:, :]\n",
    "    else:\n",
    "        splitIndex = int( testDataRatio * x.shape[0] )\n",
    "        xTest = x[ 0:splitIndex, :]\n",
    "        xTrain = x[ splitIndex:, :]\n",
    "        \n",
    "    return xTrain, xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainSplit, testSplit = train_test_split( syntheticData )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntheticData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSplit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSplit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No augmentation / noise injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data ( 0 mean, unit standard deviation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.93309992e-07]\n",
      "[ 0.70710323]\n"
     ]
    }
   ],
   "source": [
    "# find normalization statistics\n",
    "trainMeans = np.mean(trainSplit, axis=0)\n",
    "trainSTDevs = np.std(trainSplit, axis=0)\n",
    "print(trainMeans); print(trainSTDevs)\n",
    "\n",
    "# normalize [ in place / overwrite ]\n",
    "normalizedTrainData = (trainSplit - trainMeans) / (trainSTDevs + .0001)\n",
    "normalizedTestData = (testSplit - trainMeans) / (trainSTDevs + .0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate shuffled windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_into_shuffled_data_windows ( x, windowSize, advanceSamples ):\n",
    "    nWindows = int( np.floor( (x.shape[0] - windowSize)/(advanceSamples*1.0) ) )\n",
    "    # shuffle indexes\n",
    "    shuffledWindowInds = np.arange(nWindows)\n",
    "    np.random.shuffle(shuffledWindowInds)    \n",
    "        \n",
    "    nSensors = x.shape[1]\n",
    "    outputMatrix = np.zeros((nWindows, windowSize * nSensors))\n",
    "    \n",
    "    # update data matrix on a row by row basis (choosing shuffled windows per row)\n",
    "    for iWindow in range(nWindows):\n",
    "        startIndex = shuffledWindowInds[iWindow] * advanceSamples\n",
    "        endIndex = startIndex + windowSize\n",
    "        \n",
    "        # flatten/interleave sensor values\n",
    "        for iSensor in range(nSensors):\n",
    "            outputMatrix[iWindow, iSensor::nSensors] = x[startIndex:endIndex, iSensor]\n",
    "    \n",
    "    return outputMatrix, shuffledWindowInds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2757f1f7a447d687ace535c3de4e97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainMatrix, trainShuffledWindowInds = reshape_into_shuffled_data_windows(normalizedTrainData, hParams['windowSamples'], hParams['advanceSamples'])\n",
    "testMatrix, testShuffledWindowInds = reshape_into_shuffled_data_windows(normalizedTestData, hParams['windowSamples'], hParams['advanceSamples'])\n",
    "\n",
    "viz_flag = 1\n",
    "if viz_flag:\n",
    "    plt.figure()\n",
    "    plt.plot(trainMatrix[200,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74970, 30)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24970, 30)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testMatrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML/DL Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "from keras import initializers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hParams['inputOutputDimensionality'] = int( hParams['windowSamples'] * hParams['nSensors'] ) \n",
    "assert hParams['inputOutputDimensionality'] == trainMatrix.shape[1]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                480       \n",
      "=================================================================\n",
      "Total params: 1,115\n",
      "Trainable params: 1,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add( Dense( 15, input_dim = hParams['inputOutputDimensionality'], activation = 'linear'))\n",
    "model.add( Dense( 5, activation = 'sigmoid'))\n",
    "model.add( Dense( 15, activation = 'sigmoid'))\n",
    "model.add( Dense( hParams['inputOutputDimensionality'], activation = 'linear',))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c90d6d31e92401b88c968db2bb2443b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nnViz\n",
    "plt.figure()\n",
    "nnViz.visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The model needs to be compiled before being used.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-47852ef04f8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m            \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m            \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m            validation_data = (testMatrix, testMatrix) )\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m             raise RuntimeError('The model needs to be compiled '\n\u001b[0m\u001b[0;32m    852\u001b[0m                                'before being used.')\n\u001b[0;32m    853\u001b[0m         return self.model.fit(x, y,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The model needs to be compiled before being used."
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping( monitor = 'val_loss', patience = 10)\n",
    "checkpointer = ModelCheckpoint( filepath = 'synthetic_sin_weights_2.hdf5', verbose=1, save_best_only = True)\n",
    "\n",
    "model.fit( trainMatrix,\n",
    "           trainMatrix,\n",
    "           batch_size = 256, epochs = 500,\n",
    "           shuffle = True,\n",
    "           callbacks = [early_stopping, checkpointer],\n",
    "           validation_data = (testMatrix, testMatrix) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load best model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"synthetic_sin_weights_2.hdf5\")\n",
    "model.compile(optimizer = 'adam', loss = 'mse') # need to recompile model to be able to run prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot raw vs predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windowed_predict(data, windowSize):    \n",
    "    nWindows = int( data.size / (windowSize*1.0) )\n",
    "    print('number of windows: ' + str(nWindows))\n",
    "    predicted = np.zeros((data.shape[0], data.shape[1]))\n",
    "    \n",
    "    for iWindow in range(nWindows):\n",
    "        dataStartIndex = int( iWindow * windowSize )\n",
    "        dataEndIndex = dataStartIndex + windowSize\n",
    "        \n",
    "        predictedWindow = model.predict( np.transpose( data[dataStartIndex:dataEndIndex]) )\n",
    "        predicted[dataStartIndex:dataEndIndex] = np.transpose(predictedWindow)\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inject Anomalies & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5929fa5fb8674dea8414dfd698174929"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a9cf50ba20>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalySignal1 = np.exp(np.linspace(0, 1.5, 1000)) - 1\n",
    "anomalySignal2 = np.cos(np.linspace(0,2*np.pi * 1, 1000))\n",
    "anomalySignal3 = np.cos(np.linspace(0,2*np.pi * 10, 1000))\n",
    "\n",
    "anomalySignal1 = np.expand_dims(anomalySignal1, axis=1)\n",
    "anomalySignal2 = np.expand_dims(anomalySignal2, axis=1)\n",
    "anomalySignal3 = np.expand_dims(anomalySignal3, axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(anomalySignal1)\n",
    "plt.plot(anomalySignal2)\n",
    "plt.plot(anomalySignal3)\n",
    "plt.legend(['anomaly signal 1', 'anomaly signal 2', 'anomaly signal 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startIndex = 0\n",
    "endIndex = 1000\n",
    "len(anomalySignal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetData = np.concatenate( ( normalizedTestData[startIndex:endIndex], anomalySignal1, \\\n",
    "                               normalizedTestData[startIndex:endIndex], anomalySignal2, \\\n",
    "                               normalizedTestData[startIndex:endIndex], anomalySignal3 ) )\n",
    "\n",
    "anomalousInds_1 = np.arange(1000/hParams['windowSamples'], 2000/hParams['windowSamples'], dtype=int)\n",
    "anomalousInds_2 = np.arange(3000/hParams['windowSamples'], 4000/hParams['windowSamples'], dtype=int)\n",
    "anomalousInds_3 = np.arange(5000/hParams['windowSamples'], 6000/hParams['windowSamples'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of windows: 200\n"
     ]
    }
   ],
   "source": [
    "predictedData = windowed_predict ( targetData, hParams['inputOutputDimensionality'])\n",
    "error = np.sqrt((targetData - predictedData)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4940e7563ab45978fab2fbd3a3bec53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a9d09957f0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "ax1 = plt.subplot2grid((4, 1), (0, 0), rowspan=3)\n",
    "ax2 = plt.subplot2grid((4, 1), (3, 0), rowspan=1)\n",
    "\n",
    "ax1.plot(targetData)\n",
    "ax1.plot(predictedData, 'rx')\n",
    "ax1.set_title('actual vs predicted')\n",
    "ax1.legend(['actual', 'predicted'])\n",
    "\n",
    "ax2.plot(error)\n",
    "#ax2.set_ylim([0,5])\n",
    "ax2.set_title('error over time -- avg error: ' + str(round(np.mean(error),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove last two layers [ focus on bottleneck activations ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.pop()\n",
    "model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801a304bdaf841b984afee520ed1365e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nnViz\n",
    "plt.figure()\n",
    "nnViz.visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO : no overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windowed_predict_bottleneck_activation (data, windowSize, bottleneckSize):    \n",
    "    nWindows = int( data.size / (windowSize*1.0) )\n",
    "    print('number of windows: ' + str(nWindows))\n",
    "    predicted = np.zeros((nWindows, bottleneckSize))\n",
    "    \n",
    "    #dataStartIndex = 0\n",
    "    #advanceSamples = 1\n",
    "    for iWindow in range(nWindows):\n",
    "        #dataStartIndex += advanceSamples#int( iWindow * windowSize )\n",
    "        dataStartIndex = int( iWindow * windowSize )\n",
    "        dataEndIndex = dataStartIndex + windowSize\n",
    "        \n",
    "        predictedWindow = model.predict( np.transpose( data[dataStartIndex:dataEndIndex]) )\n",
    "        predicted[iWindow, :] = predictedWindow[0]\n",
    "        \n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of windows: 200\n"
     ]
    }
   ],
   "source": [
    "bottleNeckSize = model.layers[-1].get_config()['units']\n",
    "bottleneckActivations = windowed_predict_bottleneck_activation (targetData, hParams['inputOutputDimensionality'], bottleNeckSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computed conditional probabilities for sample 200 / 200\n",
      "[t-SNE] Mean sigma: 0.000284\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 10.234366\n",
      "[t-SNE] Error after 750 iterations: 10.234366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddedBottleneckActivations = TSNE(n_components = 2, perplexity = 10, learning_rate = 100, method='exact', verbose = 1).fit_transform(bottleneckActivations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0f416a5418468ab2e0e17c0d387ef4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a9d298a6a0>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(embeddedBottleneckActivations[:,0], embeddedBottleneckActivations[:,1], 'bx')\n",
    "plt.plot(embeddedBottleneckActivations[anomalousInds_1,0], embeddedBottleneckActivations[anomalousInds_1,1], 'rx')\n",
    "plt.plot(embeddedBottleneckActivations[anomalousInds_2,0], embeddedBottleneckActivations[anomalousInds_2,1], 'gx')\n",
    "plt.plot(embeddedBottleneckActivations[anomalousInds_3,0], embeddedBottleneckActivations[anomalousInds_3,1], 'kx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(embeddedBottleneckActivations[:,0], embeddedBottleneckActivations[:,1], 'bx')\n",
    "plt.plot(embeddedBottleneckActivations[anomalousInds_1,0], embeddedBottleneckActivations[anomalousInds_1,1], 'rx')\n",
    "plt.plot(embeddedBottleneckActivations[anomalousInds_2,0], embeddedBottleneckActivations[anomalousInds_2,1], 'gx')\n",
    "plt.plot(embeddedBottleneckActivations[anomalousInds_3,0], embeddedBottleneckActivations[anomalousInds_3,1], 'kx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "pca = PCA(n_components=2)\n",
    "PCA_bottleneckActivations = pca.fit_transform(bottleneckActivations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd34cd68fba4e54b330829e98fb2da2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a9d5730eb8>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(PCA_bottleneckActivations[:,0],PCA_bottleneckActivations[:,1], color='b')\n",
    "plt.scatter(PCA_bottleneckActivations[anomalousInds_1,0],PCA_bottleneckActivations[anomalousInds_1,1], color='r')\n",
    "plt.scatter(PCA_bottleneckActivations[anomalousInds_2,0],PCA_bottleneckActivations[anomalousInds_2,1], color='g')\n",
    "plt.scatter(PCA_bottleneckActivations[anomalousInds_3,0],PCA_bottleneckActivations[anomalousInds_3,1], color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mpld3\n",
    "from mpld3 import plugins, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_bottleneckActivations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(firstSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "# https://github.com/matplotlib/jupyter-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce0725c96f7468caafdb0cf1d5de542"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a8560d6f98>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " index range:  3210, 3330\n",
      " index range:  5250, 5370\n",
      " index range:  5460, 5580\n",
      " index range:  5370, 5490\n",
      " index range:  5700, 5820\n",
      " index range:  960, 1080\n",
      " index range:  990, 1110\n",
      " index range:  1110, 1230\n",
      " index range:  1140, 1260\n",
      " index range:  1170, 1290\n",
      " index range:  1230, 1350\n",
      " index range:  1530, 1650\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "\n",
    "ax1.plot( range(len(targetData)), targetData, 'x', picker = 1 )\n",
    "\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2.plot ( PCA_bottleneckActivations[:,0], PCA_bottleneckActivations[:,1], 'o', picker = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateRawPlot ( ind ):\n",
    "    print(' index range:  ' + str(int((ind-2)*30)) + ', '+ str(int((ind+2)*30)))\n",
    "    ax1.plot( list(range(int((ind-2)*30),int((ind+2)*30))), targetData[ int((ind-2)*30):int((ind+2)*30) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax.scatter(list(range(100)),np.random.rand(100))#, 'o', picker=5)  # 5 points tolerance\n",
    "#ax.plot(np.random.rand(100), 'o', picker=5)  # 5 points toleranc\n",
    "def on_pick(event):\n",
    "    if event.mouseevent.inaxes == ax2:          \n",
    "        eventArtist = event.artist\n",
    "        #xdata, ydata = eventArtist.get_data()\n",
    "        ind = event.ind\n",
    "        updateRawPlot( ind )\n",
    "        #print('on pick line:', ind, np.array([xdata[ind], ydata[ind]]).T)\n",
    "    \n",
    "cid = fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
